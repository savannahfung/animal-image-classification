{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model for Animal Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# To avoid non-essential warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mounting G-Drive to get your dataset.\n",
    "# To access Google Colab GPU; Go To: Edit >>> Netebook Settings >>> Hardware Accelarator: Select GPU.\n",
    "# Reference: https://towardsdatascience.com/google-colab-import-and-export-datasets-eccf801e2971\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Determine the project root directory\n",
    "if '__file__' in globals():\n",
    "    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\n",
    "else:\n",
    "    # Manually set the project root if __file__ is not defined (e.g., in Jupyter notebook)\n",
    "    project_root = os.path.abspath('..')\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from models.mobilenet_v3_quant import QuantizableMobileNetV3\n",
    "from src.device_manager import DeviceDataLoader, get_default_device, to_device\n",
    "from src.train_lr_scheduler import fit\n",
    "from src.evaluate import evaluate\n",
    "from src.plot import plot_losses, plot_accuracies\n",
    "from src.FLOPs_counter import print_model_parm_flops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../dataset/animals/'\n",
    "classes = os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training dataset : 6270\n"
     ]
    }
   ],
   "source": [
    "# Image Transformations\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize(112),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.CenterCrop(112),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.488), (0.2172)),\n",
    "        ])\n",
    "\n",
    "# Load Data\n",
    "dataset = ImageFolder(data_dir, transform=transform)\n",
    "\n",
    "print('Size of training dataset :', len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training dataset: 5330\n",
      "Size of validation dataset: 313\n",
      "Size of test dataset: 627\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset to training, validation, and testing category\n",
    "torch.manual_seed(10)\n",
    "val_size = len(dataset)//20\n",
    "test_size = len(dataset)//10\n",
    "train_size = len(dataset) - val_size - test_size\n",
    "\n",
    "# Random Splitting\n",
    "train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "print('Size of training dataset:', len(train_ds))\n",
    "print('Size of validation dataset:', len(val_ds))\n",
    "print('Size of test dataset:', len(test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_ds.dataset.transform = train_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, batch_size, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move data to device (GPU or CPU)\n",
    "device = get_default_device()\n",
    "train_dl = DeviceDataLoader(train_loader, device)\n",
    "val_dl = DeviceDataLoader(val_loader, device)\n",
    "test_dl = DeviceDataLoader(test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantizableMobileNetV3(\n",
      "  (model): QuantizableMobileNetV3(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): Hardswish()\n",
      "      )\n",
      "      (1): QuantizableInvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): QuantizableInvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): QuantizableInvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (4): QuantizableInvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (2): QuantizableSqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "            (skip_mul): FloatFunctional(\n",
      "              (activation_post_process): Identity()\n",
      "            )\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (5): QuantizableInvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (2): QuantizableSqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "            (skip_mul): FloatFunctional(\n",
      "              (activation_post_process): Identity()\n",
      "            )\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (6): QuantizableInvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (2): QuantizableSqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "            (skip_mul): FloatFunctional(\n",
      "              (activation_post_process): Identity()\n",
      "            )\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (7): QuantizableInvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (8): QuantizableInvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "            (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (9): QuantizableInvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (10): QuantizableInvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (11): QuantizableInvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): QuantizableSqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "            (skip_mul): FloatFunctional(\n",
      "              (activation_post_process): Identity()\n",
      "            )\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (12): QuantizableInvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): QuantizableSqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "            (skip_mul): FloatFunctional(\n",
      "              (activation_post_process): Identity()\n",
      "            )\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (13): QuantizableInvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): QuantizableSqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "            (skip_mul): FloatFunctional(\n",
      "              (activation_post_process): Identity()\n",
      "            )\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (14): QuantizableInvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): QuantizableSqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "            (skip_mul): FloatFunctional(\n",
      "              (activation_post_process): Identity()\n",
      "            )\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (15): QuantizableInvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): QuantizableSqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "            (skip_mul): FloatFunctional(\n",
      "              (activation_post_process): Identity()\n",
      "            )\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (skip_add): FloatFunctional(\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "      )\n",
      "      (16): Conv2dNormActivation(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): Hardswish()\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=960, out_features=1280, bias=True)\n",
      "      (1): Hardswish()\n",
      "      (2): Dropout(p=0.2, inplace=True)\n",
      "      (3): Linear(in_features=1280, out_features=152, bias=True)\n",
      "    )\n",
      "    (quant): QuantStub()\n",
      "    (dequant): DeQuantStub()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(classes) # 151 classes\n",
    "\n",
    "# Initialize the model\n",
    "model = QuantizableMobileNetV3(num_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to the device\n",
    "model = to_device(model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training:  [{'val_loss': 5.087026596069336, 'val_acc': 0.02812500111758709}]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model before training\n",
    "history = [evaluate(model, val_dl)]\n",
    "history_not_trained = history\n",
    "print(\"Before training: \", history_not_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizableMobileNetV3(\n",
       "  (model): QuantizableMobileNetV3(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(\n",
       "          3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "          (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "            (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "          )\n",
       "          (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "        )\n",
       "        (1): BatchNorm2d(\n",
       "          16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "          (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "        )\n",
       "        (2): Hardswish(\n",
       "          (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): QuantizableInvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): QuantizableInvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): QuantizableInvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): QuantizableInvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): QuantizableSqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(\n",
       "              72, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (fc2): Conv2d(\n",
       "              24, 72, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid(\n",
       "              (activation_post_process): FixedQParamsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), scale=tensor([0.0039], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine\n",
       "                (activation_post_process): FixedQParamsObserver()\n",
       "              )\n",
       "            )\n",
       "            (skip_mul): FloatFunctional(\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): QuantizableInvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): QuantizableSqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(\n",
       "              120, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (fc2): Conv2d(\n",
       "              32, 120, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid(\n",
       "              (activation_post_process): FixedQParamsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), scale=tensor([0.0039], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine\n",
       "                (activation_post_process): FixedQParamsObserver()\n",
       "              )\n",
       "            )\n",
       "            (skip_mul): FloatFunctional(\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): QuantizableInvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): QuantizableSqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(\n",
       "              120, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (fc2): Conv2d(\n",
       "              32, 120, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid(\n",
       "              (activation_post_process): FixedQParamsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), scale=tensor([0.0039], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine\n",
       "                (activation_post_process): FixedQParamsObserver()\n",
       "              )\n",
       "            )\n",
       "            (skip_mul): FloatFunctional(\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): QuantizableInvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): Hardswish(\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): Hardswish(\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): QuantizableInvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): Hardswish(\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): Hardswish(\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): QuantizableInvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): Hardswish(\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): Hardswish(\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): QuantizableInvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): Hardswish(\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): Hardswish(\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): QuantizableInvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): Hardswish(\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): Hardswish(\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): QuantizableSqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(\n",
       "              480, 120, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (fc2): Conv2d(\n",
       "              120, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid(\n",
       "              (activation_post_process): FixedQParamsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), scale=tensor([0.0039], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine\n",
       "                (activation_post_process): FixedQParamsObserver()\n",
       "              )\n",
       "            )\n",
       "            (skip_mul): FloatFunctional(\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): QuantizableInvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): Hardswish(\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): Hardswish(\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): QuantizableSqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(\n",
       "              672, 168, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (fc2): Conv2d(\n",
       "              168, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid(\n",
       "              (activation_post_process): FixedQParamsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), scale=tensor([0.0039], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine\n",
       "                (activation_post_process): FixedQParamsObserver()\n",
       "              )\n",
       "            )\n",
       "            (skip_mul): FloatFunctional(\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): QuantizableInvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): Hardswish(\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): Hardswish(\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): QuantizableSqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(\n",
       "              672, 168, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (fc2): Conv2d(\n",
       "              168, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid(\n",
       "              (activation_post_process): FixedQParamsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), scale=tensor([0.0039], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine\n",
       "                (activation_post_process): FixedQParamsObserver()\n",
       "              )\n",
       "            )\n",
       "            (skip_mul): FloatFunctional(\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): QuantizableInvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): Hardswish(\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): Hardswish(\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): QuantizableSqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(\n",
       "              960, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (fc2): Conv2d(\n",
       "              240, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid(\n",
       "              (activation_post_process): FixedQParamsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), scale=tensor([0.0039], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine\n",
       "                (activation_post_process): FixedQParamsObserver()\n",
       "              )\n",
       "            )\n",
       "            (skip_mul): FloatFunctional(\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): QuantizableInvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): Hardswish(\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (2): Hardswish(\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): QuantizableSqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(\n",
       "              960, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (fc2): Conv2d(\n",
       "              240, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid(\n",
       "              (activation_post_process): FixedQParamsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), scale=tensor([0.0039], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine\n",
       "                (activation_post_process): FixedQParamsObserver()\n",
       "              )\n",
       "            )\n",
       "            (skip_mul): FloatFunctional(\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(\n",
       "              960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "                (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "              )\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "            (1): BatchNorm2d(\n",
       "              160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "              (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): Conv2dNormActivation(\n",
       "        (0): Conv2d(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "            (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "          )\n",
       "          (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "        )\n",
       "        (1): BatchNorm2d(\n",
       "          960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True\n",
       "          (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "        )\n",
       "        (2): Hardswish(\n",
       "          (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(\n",
       "        in_features=960, out_features=1280, bias=True\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (1): Hardswish(\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (2): Dropout(p=0.2, inplace=True)\n",
       "      (3): Linear(\n",
       "        in_features=1280, out_features=152, bias=True\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (quant): QuantStub(\n",
       "      (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "        (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (dequant): DeQuantStub()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare for QAT\n",
    "model.train()\n",
    "model.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
    "torch.quantization.prepare_qat(model, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 334/334 [00:18<00:00, 17.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train_loss: 2.7639, val_loss: 1.8270, val_acc: 0.7795\n",
      "Epoch 2/10, Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 334/334 [00:19<00:00, 17.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], train_loss: 1.1860, val_loss: 1.4953, val_acc: 0.8170\n",
      "Epoch 3/10, Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 334/334 [00:19<00:00, 17.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], train_loss: 0.7655, val_loss: 1.4699, val_acc: 0.8226\n",
      "Epoch 4/10, Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 334/334 [00:19<00:00, 17.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], train_loss: 0.4707, val_loss: 1.0924, val_acc: 0.8726\n",
      "Epoch 5/10, Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 334/334 [00:20<00:00, 16.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], train_loss: 0.4033, val_loss: 1.2339, val_acc: 0.8719\n",
      "Epoch 6/10, Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 334/334 [00:20<00:00, 16.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], train_loss: 0.3609, val_loss: 1.2100, val_acc: 0.8639\n",
      "Epoch 7/10, Learning Rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 334/334 [00:19<00:00, 16.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], train_loss: 0.1641, val_loss: 0.8745, val_acc: 0.9156\n",
      "Epoch 8/10, Learning Rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 334/334 [00:19<00:00, 17.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], train_loss: 0.0980, val_loss: 0.7822, val_acc: 0.9062\n",
      "Epoch 9/10, Learning Rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 334/334 [00:19<00:00, 17.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], train_loss: 0.0732, val_loss: 0.7965, val_acc: 0.9156\n",
      "Epoch 10/10, Learning Rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 334/334 [00:19<00:00, 17.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], train_loss: 0.0594, val_loss: 0.7754, val_acc: 0.9344\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.001\n",
    "\n",
    "# Train the model\n",
    "history += fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training history\n",
    "torch.save(history, '../results/final_model_history.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), '../results/final_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the quantization backend\n",
    "torch.backends.quantized.engine = 'qnnpack'\n",
    "\n",
    "# Convert to quantized model for inference\n",
    "model.eval()\n",
    "model.to('cpu')\n",
    "model_int8 = torch.quantization.convert(model, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the quantized model\n",
    "torch.save(model_int8.state_dict(), '../results/final_model_quant.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracies and losses\n",
    "plot_accuracies(history)\n",
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.926562488079071\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model after training\n",
    "val = evaluate(model_int8, test_loader)\n",
    "print(\"Accuracy:\", val['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of FLOPs: 0.0029648561030626297\n",
      "Conv FLOPs: 0.0\n",
      "Linear FLOPs: 0.0\n",
      "Batch Norm FLOPs: 0.0\n",
      "ReLU FLOPs: 0.002315392\n",
      "Pooling FLOPs: 0.0006494640256278217\n"
     ]
    }
   ],
   "source": [
    "# Number of FLOPs\n",
    "input = torch.randn(1, 3, 224, 224)\n",
    "flops = print_model_parm_flops(model_int8, input, detail=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
